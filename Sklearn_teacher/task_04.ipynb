{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "224bd9a6",
   "metadata": {},
   "source": [
    "# Обучение с учителем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74fe36c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8a0cf1",
   "metadata": {},
   "source": [
    "__1.__ Импортируйте библиотеки pandas и numpy.  \n",
    "Загрузите \"Boston House Prices dataset\" из встроенных наборов данных библиотеки sklearn. Создайте датафреймы X и y из этих данных.  \n",
    "Разбейте эти датафреймы на тренировочные (X_train, y_train) и тестовые (X_test, y_test) с помощью функции train_test_split так, чтобы размер тестовой выборки составлял 30% от всех данных, при этом аргумент random_state должен быть равен 42.  \n",
    "Создайте модель линейной регрессии под названием lr с помощью класса LinearRegression из модуля sklearn.linear_model.  \n",
    "Обучите модель на тренировочных данных (используйте все признаки) и сделайте предсказание на тестовых.  \n",
    "Вычислите R2 полученных предказаний с помощью r2_score из модуля sklearn.metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fab9f849",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "\n",
    "data = boston[\"data\"]\n",
    "target = boston[\"target\"]\n",
    "feature_names = boston[\"feature_names\"]\n",
    "X = pd.DataFrame(data, columns=feature_names)\n",
    "y = pd.DataFrame(target, columns=[\"price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2bf5c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ad54362",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48199abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be17da43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.711226005748496"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2 =  r2_score(y_test, y_pred)\n",
    "R2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6beec1",
   "metadata": {},
   "source": [
    "__2.__ Создайте модель под названием model с помощью RandomForestRegressor из модуля sklearn.ensemble.  \n",
    "Сделайте агрумент n_estimators равным 1000, max_depth должен быть равен 12 и random_state сделайте равным 42.  \n",
    "Обучите модель на тренировочных данных аналогично тому, как вы обучали модель LinearRegression, но при этом в метод fit вместо датафрейма y_train поставьте y_train.values[:, 0], чтобы получить из датафрейма одномерный массив Numpy, так как для класса RandomForestRegressor в данном методе для аргумента y предпочтительно применение массивов вместо датафрейма.  \n",
    "Сделайте предсказание на тестовых данных и посчитайте R2. Сравните с результатом из предыдущего задания.  \n",
    "Напишите в комментариях к коду, какая модель в данном случае работает лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abc48621",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=1000, max_depth=12, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b1350c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=12, n_estimators=1000, random_state=42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train.values[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f48c5218",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d50fad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87472606157312"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2_ = r2_score(y_test, y_pred2)\n",
    "R2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6e9cfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor работает лучше, чем LinearRegression\n"
     ]
    }
   ],
   "source": [
    "if R2 > R2_:\n",
    "    print(\"LinearRegression работает лучше, чем RandomForestRegressor\")\n",
    "elif R2 < R2_:\n",
    "    print(\"RandomForestRegressor работает лучше, чем LinearRegression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927bc2a5",
   "metadata": {},
   "source": [
    "__3*.__ Вызовите документацию для класса RandomForestRegressor, найдите информацию об атрибуте feature_importances_.\n",
    "С помощью этого атрибута найдите сумму всех показателей важности, установите, какие два признака показывают наибольшую важность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39654484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "- LSTAT    % lower status of the population\n",
      "- RM       average number of rooms per dwelling\n"
     ]
    }
   ],
   "source": [
    "importances = model.feature_importances_\n",
    "print(np.sum(importances))\n",
    "indices = np.argsort(importances)[::-1]\n",
    "i0, i1 = feature_names[indices][:2]\n",
    "\n",
    "lines = boston[\"DESCR\"].split(\"\\n\")\n",
    "for i in (i0, i1):\n",
    "    for line in lines:\n",
    "        if i in line:\n",
    "            print(line.strip())\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c18dcf",
   "metadata": {},
   "source": [
    "__4.__ В этом задании мы будем работать с датасетом, с которым мы уже знакомы по домашнему заданию по библиотеке Matplotlib, это датасет Credit Card Fraud Detection. Для этого датасета мы будем решать задачу классификации - будем определять, какие из транзакциции по кредитной карте являются мошенническими. Данный датасет сильно несбалансирован (так как случаи мошенничества относительно редки), так что применение метрики accuracy не принесёт пользы и не поможет выбрать лучшую модель. Мы будем вычислять AUC, то есть площадь под кривой ROC.  \n",
    "Импортируйте из соответствующих модулей RandomForestClassifier, GridSearchCV и train_test_split.  \n",
    "Загрузите датасет creditcard.csv и создайте датафрейм df.  \n",
    "С помощью метода value_counts с аргументом normalize=True убедитесь в том, что выборка несбалансирована. Используя метод info, проверьте, все ли столбцы содержат числовые данные и нет ли в них пропусков.Примените следующую настройку, чтобы можно было просматривать все столбцы датафрейма: pd.options.display.max_columns = 100.  \n",
    "Просмотрите первые 10 строк датафрейма df.  \n",
    "Создайте датафрейм X из датафрейма df, исключив столбец Class.  \n",
    "Создайте объект Series под названием y из столбца Class.  \n",
    "Разбейте X и y на тренировочный и тестовый наборы данных при помощи функции train_test_split, используя аргументы: test_size=0.3, random_state=100, stratify=y.  \n",
    "У вас должны получиться объекты X_train, X_test, y_train и y_test.  \n",
    "Просмотрите информацию о их форме.  \n",
    "Для поиска по сетке параметров задайте такие параметры: parameters = [{'n_estimators': [10, 15], 'max_features': np.arange(3, 5), 'max_depth': np.arange(4, 7)}]  \n",
    "Создайте модель GridSearchCV со следующими аргументами: estimator=RandomForestClassifier(random_state=100), param_grid=parameters, scoring='roc_auc', cv=3.  \n",
    "Обучите модель на тренировочном наборе данных (может занять несколько минут).  \n",
    "Просмотрите параметры лучшей модели с помощью атрибута best_params_.  \n",
    "Предскажите вероятности классов с помощью полученнной модели и метода predict_proba.  \n",
    "Из полученного результата (массив Numpy) выберите столбец с индексом 1 (вероятность класса 1) и запишите в массив y_pred_proba.  Из модуля sklearn.metrics импортируйте метрику roc_auc_score.  \n",
    "Вычислите AUC на тестовых данных и сравните с результатом, полученным на тренировочных данных, используя в качестве аргументов массивы y_test и y_pred_proba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b22bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ccd3b35",
   "metadata": {},
   "source": [
    "1). Загрузите датасет Wine из встроенных датасетов sklearn.datasets с помощью функции load_wine в переменную data.  \n",
    "2). Полученный датасет не является датафреймом. Это структура данных, имеющая ключи аналогично словарю. Просмотрите тип данных этой структуры данных и создайте список data_keys, содержащий её ключи.  \n",
    "3). Просмотрите данные, описание и названия признаков в датасете. Описание нужно вывести в виде привычного, аккуратно оформленного текста, без обозначений переноса строки, но с самими переносами и т.д.  \n",
    "4). Сколько классов содержит целевая переменная датасета? Выведите названия классов.  \n",
    "5). На основе данных датасета (они содержатся в двумерном массиве Numpy) и названий признаков создайте датафрейм под названием X.  \n",
    "6). Выясните размер датафрейма X и установите, имеются ли в нем пропущенные значения.  \n",
    "7). Добавьте в датафрейм поле с классами вин в виде чисел, имеющих тип данных numpy.int64. Название поля - 'target'.  \n",
    "8). Постройте матрицу корреляций для всех полей X. Дайте полученному датафрейму название X_corr.  \n",
    "9). Создайте список high_corr из признаков, корреляция которых с полем target по абсолютному значению превышает 0.5 (причём, само поле target не должно входить в этот список).  \n",
    "10). Удалите из датафрейма X поле с целевой переменной. Для всех признаков, названия которых содержатся в списке high_corr, вычислите квадрат их значений и добавьте в датафрейм X соответствующие поля с суффиксом '_2', добавленного к первоначальному названию признака. Итоговый датафрейм должен содержать все поля, которые, были в нем изначально, а также поля с признаками из списка high_corr, возведёнными в квадрат. Выведите описание полей датафрейма X с помощью метода describe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75136fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
